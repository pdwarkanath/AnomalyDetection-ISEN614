{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a project report for the final project for the ISEN 614 - Advanced Quality Control class taught in Fall 2016 at Texas A&M University by Dr. Yu Ding.\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "The  objective of this project was to identify the in-control and out-of-control samples. Due to high dimensionality, the noise components can add up to a great magnitude. As a result, the aggregated noise effect can overwhelm the signal effects thus making it harder to reject the null hypothesis. This phenomenon is known as curse of dimensionality. In this report since the number of dimensions are very high, we used principal component analysis (PCA) as the data reduction tool to reduce the data points and then used the Hotelling $T^2$ chart on the reduced data to isolate the in-control samples.\n",
    "\n",
    "First, we calculated the mean vector and covariance matrix of the given data. Then, we calculated eigenvalues and eigenvectors of S to find the reduced dimension. These eigenvectors were used to form principal components from the original data. For the S matrix, we calculated the eigenvalues and arranged them in descending order. Thereafter, we plotted a graph and observed that the value of L for which MDL is minimum is 35. As 35 Principal Components (PC‚Äôs) are not nearly small enough we then used scree plot i.e. the plot of eigenvalues against the number of principal components to further compress data and reduce the Principal Components (PCs). From the scree plot, we observed that there is a bend where the x-axis value is 4. Therefore, we chose only the first 4 principal components for our analysis.\n",
    "\n",
    "For Principal Component Analysis (PCA), we calculated the vector $y$ of principal components and then performed Phase I analysis on $y$. While performing the Phase I analysis of $y$, we approximated the upper control limit to 9.49 using a $\\chi^2$ distribution. We then plotted the Hotelling $T^2$ statistic for each sample. To isolate in-control data, we removed out-of-control samples and recalculated the $T^2$ statistic till we were left with only the in-control samples. i.e there were 461 in-control samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open excel file using pandas\n",
    "\n",
    "book = pd.read_excel(\"project_dataset.xlsx\", header =None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 552\n",
      "p = 209\n"
     ]
    }
   ],
   "source": [
    "n, p = book.shape\n",
    "print(f'n = {n}')\n",
    "print(f'p = {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding The Problem\n",
    "\n",
    "The problem at hand has 552 samples, each with 209 data points.\n",
    "\n",
    "This can be denoted with X as a matrix of shape 552x209\n",
    "\n",
    "The $\\mu_0$ and $\\sum_0$ for this data are not known. Hence, this is a Phase I analysis with a sample size of 1. We will use the mean $\\overline{X}$ and covariance matrix $S$ of the samples to estimate $\\mu_0$ and $\\sum_0$ for the data.\n",
    "\n",
    "Since the number of dimensions is very high, we will first reduce data using principal component analysis and then use the Hotelling chart to isolate in-control data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reduction\n",
    "\n",
    "For Principal Component Analysis (PCA), we need $\\overline{X}$ and $S$ for the sample.\n",
    "\n",
    "### Sample statistics:\n",
    "\n",
    "$$ \\overline{X} = \\frac{1}{n} \\sum_{i=1}^{n}X_i $$\n",
    "\n",
    "where $X_i$ is one row of the matrix\n",
    "\n",
    "$$ S = \\frac{1}{n-1} (X - \\overline{X})^T.(X - \\overline{X}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $S$ is the covariance matrix of variables, it is of shape 209x209.\n",
    "\n",
    "Fortunately, numpy has functions available to calculate mean and covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbar = np.mean(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.cov(X, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigen Values\n",
    "\n",
    "We will calculate eigenvalues and eigenvectors of $S$ to find the reduced dimension. These eigenvectors will be used to form principal components from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = np.linalg.eig(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDL Values\n",
    "\n",
    "We plot a graph using the formula:\n",
    "\n",
    "$$ MDL (l) = n(p-l)log(\\frac{ùëé_ùëô}{ùëî_ùëô}) + \\frac{l(2p ‚Äì l)}{2}log(n) $$\n",
    "\n",
    "Where $ùëé_ùëô ,ùëî_ùëô$ are the arithmetic and geometric means respectively of the smallest (p ‚Äì l) eigenvalues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/MDL_Values.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scree Plot\n",
    "![](images/Scree_plot.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prinicipal Component Analysis\n",
    "\n",
    "For Principal Component Analysis (PCA), we calculate the vector y, such that\n",
    "\n",
    "$$ ùë¶= X.ùëí$$ \n",
    "\n",
    "Where $ùëí_j$ is the $j^{ùë°‚Ñé}$ eigenvector of $S$ and $j \\in \\{1,..,4\\}$.\n",
    "\n",
    "As there are n (= 552) samples, $y$ is of shape 552x4\n",
    "\n",
    "We will now perform Phase I analysis on $y$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase I Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upper Control Limit\n",
    "\n",
    "For Phase I analysis of $y$, we approximate the upper control limit using\n",
    "\n",
    "$$ ùëàùê∂ùêø = \\chi^2_{1 ‚àí\\alpha}  (p) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCL = 9.487729036781154\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "p = 4\n",
    "UCL = chi2.ppf(1 - alpha, p)\n",
    "print(f'UCL = {UCL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have chosen $\\alpha = 0.05$. $p$ is the reduced dimension, hence $p = 4$. looking up the chi-square distribution table\n",
    "\n",
    "$$ UCL = 9.49 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the Hotelling $T^2$ statistic for each sample. To isolate in-control data, we will remove out-of-control samples and recalculate the $T^2$ statistic till we are left with only in-control samples.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $T^2$ statistic, we use:\n",
    "\n",
    "$$ T^2 = (y_i - \\overline{y})^T S_y^{-1} (y_i - \\overline{y}) $$\n",
    "\n",
    "Where $\\overline{y}$ is the mean of $y$, $S$ is the covariance matrix of $y$ and $i \\in \\{1,2, ..., n\\}$ is the sample number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be calculated the same way as we did for X\n",
    "\n",
    "$$ \\overline{y} = \\frac{1}{n} \\sum_{i=1}^{n}y_i $$\n",
    "\n",
    "where $y_i$ is one row of the $y$ matrix\n",
    "\n",
    "$$ S_y = \\frac{1}{n-1} (y - \\overline{y})^T.(y - \\overline{y}) $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hotelling Statistic First Iteration\n",
    "![](images/Tsquared_First_Iteration.png)\n",
    "In this plot, it can be seen that there are several samples that are out of control"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hotelling Statistic In-Control Samples\n",
    "![](images/Tsquared_In-control.png)\n",
    "In this plot, all samples are in control. In total there are 461 in-control samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
